{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1) install pakages and **libraries**"
      ],
      "metadata": {
        "id": "TnvWtc3HRpzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhmMZA86Aaqo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Install the necessary packages\n",
        "\n",
        "!pip install transformers -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_community -q\n",
        "!pip install sentence_transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "4S0rB67aHLre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Initialize nvidia llama-3.1-405b-instruct\n"
      ],
      "metadata": {
        "id": "oauZXHxBR8Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-nvidia-ai-endpoints -q # Install the missing package\n"
      ],
      "metadata": {
        "id": "cqKEfuuaIRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "client = ChatNVIDIA(\n",
        "  model=\"meta/llama-3.1-405b-instruct\",\n",
        "  api_key=\"API_KEY",\n",
        "  temperature=0.2,\n",
        "  top_p=0.7,\n",
        "  max_tokens=100,\n",
        ")\n",
        "\n",
        "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
        "  print(chunk.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnQgsbUoH3Wl",
        "outputId": "a046add4-d45c-4d0a-891c-1b6165835647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a limerick about GPU computing:\n",
            "\n",
            "There once was a GPU so fine,\n",
            "Whose parallel processing was divine.\n",
            "It crunched with great zest,\n",
            "Through data at rest,\n",
            "And made complex tasks truly shine."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Initialize Output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm-BV30wTDxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i) prompt template"
      ],
      "metadata": {
        "id": "aEumryxKVbGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages(    [\n",
        "       (\"system\",\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "       (\"user\", \"{question}\")\n",
        "    ])"
      ],
      "metadata": {
        "id": "NlAI3GlqJKj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Output Parser"
      ],
      "metadata": {
        "id": "MxhBBt6LVpxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize the string output parser\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XezPpVyxJO-K",
        "outputId": "7a035fac-b2f9-48b6-ef80-8d2cdc642657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Becoming a billionaire requires a combination of several key factors, including:\n",
            "\n",
            "1. **Vision and innovation**: Identify a unique opportunity or problem to solve, and create a innovative solution that can scale.\n",
            "2. **Hard work and dedication**: Be willing to put in the time and effort required to build and grow a successful business or investment portfolio.\n",
            "3. **Strategic risk-taking**: Take calculated risks to achieve high returns, but also be prepared to learn from failures.\n",
            "4. **Business acumen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii) Chain and final question"
      ],
      "metadata": {
        "id": "6IzJV7FJXv4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain the prompt, LLM, and output parser\n",
        "chain = prompt | client | parser\n",
        "\n",
        "question = \"how to becom billioner?\"\n",
        "\n",
        "response = chain.invoke({\"question\": question})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LQy5H7XZLaCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
